---
layout: post
title: "Harmonisierte Standards und KI - Warum der Hype?"
date: 2025-07-22
last_modified_at: 2025-07-22
categories: [Standards]
tags: [AI Act, JTC 21]
excerpt: "Ein kurzer Einblick in die Logik hinter harmonisierten Standards der EU und warum sie zentral für die Compliance mit dem EU Ai Act sind."
---

Mit dem [AI
Act](https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence)
ist zum 02. August 2024 die umfangreiche KI-Reglierung der EU in Kraft
getreten. Die enthaltenen Auflagen kommen dabei
[stufenweise](https://artificialintelligenceact.eu/de/implementation-timeline/)
zur Anwendung.

Hier kommen auch schon der Begriff des *Harmonisierten Standards* ins
Bild, der fast schon als Buzz-Word der KI-Regulierung gesehen werden
kann. Aber was steckt eigentlich hinter diesem etwas sperrigen
Begriff? 

### Was sind harmonisierte Standards?
Harmonisierte Standards sind ein Werkzeug im Kontext von
EU-Gesetzgebung. Sie erleichtern es Organisationen, die Konformität
mit EU-Regulatorik nachzuweisen. Man könnte es vereinfachend
zusammenfassen als
**Standard-Konformität=Gesetzes-Konformität**.

Wie entsteht ein harmonisierter Standard? Zunächst stellt die
EU-Kommission eine Anfrage zur Entwicklung des Standards an eines oder
mehrere der europäischen Standardisierungsgremien (CEN, CENELEC oder
ETSI). Diese entwickeln entsprechende Standards, welche dann noch "den
Stempel" der EU-Kommission in Form einer offiziellen Veröffentlichung
im Amtsblatt benötigt.

Verwendet ein Produkthersteller einen harmonisierten Standard, so wird
die Gesetzeskonformität angenommen. Ein Nachweis kann bspw. durch eine
Zertifizierung gegen den Standard erfolgen.

Der Einsatz eines harmonisierten Standards ist nicht
verpflichtend. Allerdings kann der Aufwand, Gesetzeskonformität
nachzuweisen wesentlich höher sein. 

Kurz am Beispiel erläutert: Eine Firma, nennen wir Sie Acme Inc.,
vertreibt ein Produkt in der EU. Die deutsche Aufsichtsbehörde tritt
an Acme Inc. heran und bittet um Nachweis, dass die entsprechende
EU-Produktsicherheits-Richtlinie erfüllt ist. Acme Inc. ist
zuversichtlich, denn die Entwicklung wurde gemäß dem *Standard
Super-S* durchgeführt und zertifiziert.

Hier ergeben sich nun zwei Szenarien:
* Der Standard *Super-S* ist ein harmonisierter Standard der EU: Die
  Aufsichtsbehörde erhält das Zertifikat und geht daher davon aus,
  dass das Produkt auch konform mit der entsprechenden Richtlinie ist.
* Der Standard *Super-S* ist _kein_ harmonisierter Standard: Die
  Aufsichtsbehörde erhält das Zertifikat. Der Sachbearbeiter äußert
  jedoch Zweifel, ob das Verfahren nach *Super-S* wirklich alle
  Vorgaben der EU-Richtlinie berücksichtigt. Acme Inc. muss daher
  detailliert darlegen, wie der Standard die Richtlinie erfüllt.
  
Es wird deutlich: Die Verwendung eines harmonisierten Standards
reduziert Aufwand und Risiko erheblich. Das Verfahren um
Gesetzeskonformität zu erreichen ist klar definiert, der Nachweis ist
einfacher.

### Warum sind sie für KI besonders relevant
Im [Kontext des AI
Acts](https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=OJ:L_202401689#art_40)
wird besonders gespannt auf die Inhalte der Standards gewartet.

Ein offensichtlicher Grund dafür dürfte sein, dass
wir im Bereich KI in einem sehr neuen, dynamischen Umfeld sind. Die Auflagen
für hoch-riskante KI-Systeme sind hoch, der Erfahrungsschatz
gering. 

Insofern hoffen Organisationen auf dringend notwendige Orientierung,
um Rechtssicherheit zu erhalten. Daneben besteht sicher auch der
Wunsch zu verstehen, wie die Konformität mit angemessenem Aufwand
operationalisierbar ist.

### Status quo bei den harmonisierten KI-Standards
Die EU-Kommission hat in ihrer
[Standardisierungs-Anfrage](https://ec.europa.eu/transparency/documents-register/detail?ref=C(2023)3215&lang=en)
Arbeit zu zehn Themenbereichen angefordert:
* Risk Management Systems (Risiko Management)
* Governance and Quality of Datasets (Daten-Governance und -Qualität)
* Record Keeping (Aufzeichnungspflichten)
* Transparency and Information Provisions (Transparenz und Informationsbereitstellung)
* Human Oversight (Beaufsichtigung von Systemen)
* Accuracy Specification (Präzision)
* Robustness Specification (Robustheit)
* Cybersecurity Specification (Cyber-Sicherheit)
* Quality Management, incl. post-market Monitoring (Qualitätskontrolle)
* Conformity Assessment 

Die Anfrage wird im Rahmen des Joint Technical Committees 21 ([JTC
21](https://www.cencenelec.eu/areas-of-work/cen-cenelec-topics/artificial-intelligence/))
von CEN und CENELEC bearbeitet. Im April 2025 erklärten CEN-CENELEC,
dass die [Standardisierung sich
verzögern](https://www.euronews.com/next/2025/04/16/eu-standards-bodies-flag-delays-to-work-on-ai-act)
werde. Demnach werden die Standards frühestens in 2026 zur Verfügung
stehen, wobei im Laufe des Jahres Entwurfsstände für die weitere
Überarbeitung und Abstimmung veröffentlicht werden sollen.

Dies erzeugt natürlich Unsicherheit, denn die finale Stufe des AI Acts
wird im August 2026 in Kraft treten. Sogar wenn wir von einer
Veröffentlichung der Standards vor diesem Termin ausgehen, ist die
Zeit für eine Umsetzung oder gar Zertifizierung mehr als knapp.

### Chancen und Herausforderungen
Mit dem Mechanismus der harmonisierten Standards möchte die EU den
Firmen ein Werkzeug an die Hand geben, das Rechtssicherheit erzeugt
und einen fairen Zugang zum Binnenmarkt. Das ist ein zu begrüßendes
Ziel.  

*Gute* Standards können hier entscheidende Vorteile haben: 
* Sie ermöglichen eine effiziente Umsetzung innerhalb von Firmen.
* Sie schaffen Rechtssicherheit und einen fairen Marktzugang.
* Sie etablieren ein gleichwertiges Schutzniveau. 

Ein Blick auf den gewählten Ansatz und die Zeitleiste zeigt allerdings
auch die mögliche Schwäche dieses großen Unterfangens:
* Die Zeit ist knapp und Standardisierung ist ein sehr inklusiver
  Prozess, der Zeit benötigt. Es besteht die Gefahr, dass die
  Ergebnisse eher minimale Kompromisse sind und wenig praktische Tiefe
  haben.
* KI ist eine sich dynamisch entwickelnde Technologie. Der erste
  Entwurf des EU AI Acts erschien fast zwei Jahre vor der Einführung
  von ChatGPT. Regelungen zu LLMs waren nicht enthalten. Bei der
  Standardisierung sehen wir ebenfalls einen längeren Prozess mit dem
  Risiko, dass neuere Entwicklungen nicht erfasst werden können. Es
  besteht also auch hier ein Risiko, dass Standards zu rigide sind
  (und damit Innovation einschränken) oder aber zu high-level (und
  damit wenig umsetzbar bzw. effizienzsteigernd).

### Fazit: Was bedeutet das für die Praxis
Wie gezeigt bietet Standardisierung Vorteile, von Effizienz zu
Rechtsicherheit. Die harmonisierten Standards können hier ein
mächtiges, hilfreiches Werkzeug sein. Mir persönlich erscheint das
europäische Standardisierungsprojekt zum AI Act allerdings sehr
riskant: Die Zeitleiste ist knapp und das Risiko hoch, dass die
Standards ggf. nicht die gewünschte Tiefe aufweisen.

Durch das Warten auf die Standards der EU wird auch ein Stück weit die
Hoffnung genährt, dass mit der Veröffentlichung "alles klar sein
wird". Das ist sehr wahrscheinlich allerdings nicht der Fall und
Unternehmen verlieren wertvolle Zeit.

Der Ratschlag an alle Unternehmen, die sich mit KI intensiv befassen
oder gar Hochrisiko-Anwendungen entwickeln kann daher nur lauten:
Bereits jetzt auf Basis existierender Ansätze (Standard, Best
Practices) tätig werden und die geforderten Komponenten wie
Risiko-Management, Qualitätssicherung und co. gezielt angehen.

